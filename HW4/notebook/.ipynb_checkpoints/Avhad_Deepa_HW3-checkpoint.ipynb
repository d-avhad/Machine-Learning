{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Deepa_Avhad_HW3</h1></center>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Deepa Avhad\n",
    "<br>\n",
    "Github Username: d-avhad\n",
    "<br>\n",
    "USC ID: 7023239026 <br>\n",
    "\n",
    "References:\n",
    "1. https://stats.stackexchange.com/questions/50807/features-for-time-series-classification\n",
    "2. https://stats.stackexchange.com/questions/264392/how-to-extract-features-from-time-series-data\n",
    "3. https://www.statology.org/bootstrapping-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bootstrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "import bootstrapped.bootstrap as bs\n",
    "import bootstrapped.stats_functions as boot_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total folders: ['bending1', 'bending2', 'bendingType.pdf', 'cycling', 'lying', 'sensorsPlacement.pdf', 'sitting', 'standing', 'walking']\n",
      "Total Instances:  88\n",
      "Training Instances:  69\n",
      "Testing Instances:  19\n",
      "Each Data File has 480 rows and 6 time-series columns\n",
      "\n",
      "six time series features --\n",
      " 1. avg_rss12\n",
      " 2. var_rss12\n",
      " 3. avg_rss13\n",
      " 4. var_rss13\n",
      " 5. avg_rss23\n",
      " 6. var_rss23\n",
      "\n",
      "\n",
      " ------ All file paths:  88  Instances \n",
      "\n",
      "1 .  ../data/AReM/bending1/dataset1.csv\n",
      "2 .  ../data/AReM/bending1/dataset2.csv\n",
      "3 .  ../data/AReM/bending2/dataset1.csv\n",
      "4 .  ../data/AReM/bending2/dataset2.csv\n",
      "5 .  ../data/AReM/lying/dataset1.csv\n",
      "6 .  ../data/AReM/lying/dataset2.csv\n",
      "7 .  ../data/AReM/lying/dataset3.csv\n",
      "8 .  ../data/AReM/cycling/dataset1.csv\n",
      "9 .  ../data/AReM/cycling/dataset2.csv\n",
      "10 .  ../data/AReM/cycling/dataset3.csv\n",
      "11 .  ../data/AReM/sitting/dataset1.csv\n",
      "12 .  ../data/AReM/sitting/dataset2.csv\n",
      "13 .  ../data/AReM/sitting/dataset3.csv\n",
      "14 .  ../data/AReM/standing/dataset1.csv\n",
      "15 .  ../data/AReM/standing/dataset2.csv\n",
      "16 .  ../data/AReM/standing/dataset3.csv\n",
      "17 .  ../data/AReM/walking/dataset1.csv\n",
      "18 .  ../data/AReM/walking/dataset2.csv\n",
      "19 .  ../data/AReM/walking/dataset3.csv\n",
      "20 .  ../data/AReM/bending1/dataset3.csv\n",
      "21 .  ../data/AReM/bending1/dataset4.csv\n",
      "22 .  ../data/AReM/bending1/dataset5.csv\n",
      "23 .  ../data/AReM/bending1/dataset6.csv\n",
      "24 .  ../data/AReM/bending1/dataset7.csv\n",
      "25 .  ../data/AReM/bending2/dataset3.csv\n",
      "26 .  ../data/AReM/bending2/dataset4.csv\n",
      "27 .  ../data/AReM/bending2/dataset5.csv\n",
      "28 .  ../data/AReM/bending2/dataset6.csv\n",
      "29 .  ../data/AReM/lying/dataset10.csv\n",
      "30 .  ../data/AReM/lying/dataset11.csv\n",
      "31 .  ../data/AReM/lying/dataset12.csv\n",
      "32 .  ../data/AReM/lying/dataset13.csv\n",
      "33 .  ../data/AReM/lying/dataset14.csv\n",
      "34 .  ../data/AReM/lying/dataset15.csv\n",
      "35 .  ../data/AReM/lying/dataset4.csv\n",
      "36 .  ../data/AReM/lying/dataset5.csv\n",
      "37 .  ../data/AReM/lying/dataset6.csv\n",
      "38 .  ../data/AReM/lying/dataset7.csv\n",
      "39 .  ../data/AReM/lying/dataset8.csv\n",
      "40 .  ../data/AReM/lying/dataset9.csv\n",
      "41 .  ../data/AReM/cycling/dataset10.csv\n",
      "42 .  ../data/AReM/cycling/dataset11.csv\n",
      "43 .  ../data/AReM/cycling/dataset12.csv\n",
      "44 .  ../data/AReM/cycling/dataset13.csv\n",
      "45 .  ../data/AReM/cycling/dataset14.csv\n",
      "46 .  ../data/AReM/cycling/dataset15.csv\n",
      "47 .  ../data/AReM/cycling/dataset4.csv\n",
      "48 .  ../data/AReM/cycling/dataset5.csv\n",
      "49 .  ../data/AReM/cycling/dataset6.csv\n",
      "50 .  ../data/AReM/cycling/dataset7.csv\n",
      "51 .  ../data/AReM/cycling/dataset8.csv\n",
      "52 .  ../data/AReM/cycling/dataset9.csv\n",
      "53 .  ../data/AReM/sitting/dataset10.csv\n",
      "54 .  ../data/AReM/sitting/dataset11.csv\n",
      "55 .  ../data/AReM/sitting/dataset12.csv\n",
      "56 .  ../data/AReM/sitting/dataset13.csv\n",
      "57 .  ../data/AReM/sitting/dataset14.csv\n",
      "58 .  ../data/AReM/sitting/dataset15.csv\n",
      "59 .  ../data/AReM/sitting/dataset4.csv\n",
      "60 .  ../data/AReM/sitting/dataset5.csv\n",
      "61 .  ../data/AReM/sitting/dataset6.csv\n",
      "62 .  ../data/AReM/sitting/dataset7.csv\n",
      "63 .  ../data/AReM/sitting/dataset8.csv\n",
      "64 .  ../data/AReM/sitting/dataset9.csv\n",
      "65 .  ../data/AReM/standing/dataset10.csv\n",
      "66 .  ../data/AReM/standing/dataset11.csv\n",
      "67 .  ../data/AReM/standing/dataset12.csv\n",
      "68 .  ../data/AReM/standing/dataset13.csv\n",
      "69 .  ../data/AReM/standing/dataset14.csv\n",
      "70 .  ../data/AReM/standing/dataset15.csv\n",
      "71 .  ../data/AReM/standing/dataset4.csv\n",
      "72 .  ../data/AReM/standing/dataset5.csv\n",
      "73 .  ../data/AReM/standing/dataset6.csv\n",
      "74 .  ../data/AReM/standing/dataset7.csv\n",
      "75 .  ../data/AReM/standing/dataset8.csv\n",
      "76 .  ../data/AReM/standing/dataset9.csv\n",
      "77 .  ../data/AReM/walking/dataset10.csv\n",
      "78 .  ../data/AReM/walking/dataset11.csv\n",
      "79 .  ../data/AReM/walking/dataset12.csv\n",
      "80 .  ../data/AReM/walking/dataset13.csv\n",
      "81 .  ../data/AReM/walking/dataset14.csv\n",
      "82 .  ../data/AReM/walking/dataset15.csv\n",
      "83 .  ../data/AReM/walking/dataset4.csv\n",
      "84 .  ../data/AReM/walking/dataset5.csv\n",
      "85 .  ../data/AReM/walking/dataset6.csv\n",
      "86 .  ../data/AReM/walking/dataset7.csv\n",
      "87 .  ../data/AReM/walking/dataset8.csv\n",
      "88 .  ../data/AReM/walking/dataset9.csv\n",
      "\n",
      " ------- Total test files:  19 Instances \n",
      "\n",
      "1 .   ../data/AReM/bending1/dataset1.csv\n",
      "2 .   ../data/AReM/bending1/dataset2.csv\n",
      "3 .   ../data/AReM/bending2/dataset1.csv\n",
      "4 .   ../data/AReM/bending2/dataset2.csv\n",
      "5 .   ../data/AReM/lying/dataset1.csv\n",
      "6 .   ../data/AReM/lying/dataset2.csv\n",
      "7 .   ../data/AReM/lying/dataset3.csv\n",
      "8 .   ../data/AReM/cycling/dataset1.csv\n",
      "9 .   ../data/AReM/cycling/dataset2.csv\n",
      "10 .   ../data/AReM/cycling/dataset3.csv\n",
      "11 .   ../data/AReM/sitting/dataset1.csv\n",
      "12 .   ../data/AReM/sitting/dataset2.csv\n",
      "13 .   ../data/AReM/sitting/dataset3.csv\n",
      "14 .   ../data/AReM/standing/dataset1.csv\n",
      "15 .   ../data/AReM/standing/dataset2.csv\n",
      "16 .   ../data/AReM/standing/dataset3.csv\n",
      "17 .   ../data/AReM/walking/dataset1.csv\n",
      "18 .   ../data/AReM/walking/dataset2.csv\n",
      "19 .   ../data/AReM/walking/dataset3.csv\n",
      "\n",
      " ------- Total train files:  69 Instances \n",
      "\n",
      "1 .   ../data/AReM/bending1/dataset3.csv\n",
      "2 .   ../data/AReM/bending1/dataset4.csv\n",
      "3 .   ../data/AReM/bending1/dataset5.csv\n",
      "4 .   ../data/AReM/bending1/dataset6.csv\n",
      "5 .   ../data/AReM/bending1/dataset7.csv\n",
      "6 .   ../data/AReM/bending2/dataset3.csv\n",
      "7 .   ../data/AReM/bending2/dataset4.csv\n",
      "8 .   ../data/AReM/bending2/dataset5.csv\n",
      "9 .   ../data/AReM/bending2/dataset6.csv\n",
      "10 .   ../data/AReM/lying/dataset10.csv\n",
      "11 .   ../data/AReM/lying/dataset11.csv\n",
      "12 .   ../data/AReM/lying/dataset12.csv\n",
      "13 .   ../data/AReM/lying/dataset13.csv\n",
      "14 .   ../data/AReM/lying/dataset14.csv\n",
      "15 .   ../data/AReM/lying/dataset15.csv\n",
      "16 .   ../data/AReM/lying/dataset4.csv\n",
      "17 .   ../data/AReM/lying/dataset5.csv\n",
      "18 .   ../data/AReM/lying/dataset6.csv\n",
      "19 .   ../data/AReM/lying/dataset7.csv\n",
      "20 .   ../data/AReM/lying/dataset8.csv\n",
      "21 .   ../data/AReM/lying/dataset9.csv\n",
      "22 .   ../data/AReM/cycling/dataset10.csv\n",
      "23 .   ../data/AReM/cycling/dataset11.csv\n",
      "24 .   ../data/AReM/cycling/dataset12.csv\n",
      "25 .   ../data/AReM/cycling/dataset13.csv\n",
      "26 .   ../data/AReM/cycling/dataset14.csv\n",
      "27 .   ../data/AReM/cycling/dataset15.csv\n",
      "28 .   ../data/AReM/cycling/dataset4.csv\n",
      "29 .   ../data/AReM/cycling/dataset5.csv\n",
      "30 .   ../data/AReM/cycling/dataset6.csv\n",
      "31 .   ../data/AReM/cycling/dataset7.csv\n",
      "32 .   ../data/AReM/cycling/dataset8.csv\n",
      "33 .   ../data/AReM/cycling/dataset9.csv\n",
      "34 .   ../data/AReM/sitting/dataset10.csv\n",
      "35 .   ../data/AReM/sitting/dataset11.csv\n",
      "36 .   ../data/AReM/sitting/dataset12.csv\n",
      "37 .   ../data/AReM/sitting/dataset13.csv\n",
      "38 .   ../data/AReM/sitting/dataset14.csv\n",
      "39 .   ../data/AReM/sitting/dataset15.csv\n",
      "40 .   ../data/AReM/sitting/dataset4.csv\n",
      "41 .   ../data/AReM/sitting/dataset5.csv\n",
      "42 .   ../data/AReM/sitting/dataset6.csv\n",
      "43 .   ../data/AReM/sitting/dataset7.csv\n",
      "44 .   ../data/AReM/sitting/dataset8.csv\n",
      "45 .   ../data/AReM/sitting/dataset9.csv\n",
      "46 .   ../data/AReM/standing/dataset10.csv\n",
      "47 .   ../data/AReM/standing/dataset11.csv\n",
      "48 .   ../data/AReM/standing/dataset12.csv\n",
      "49 .   ../data/AReM/standing/dataset13.csv\n",
      "50 .   ../data/AReM/standing/dataset14.csv\n",
      "51 .   ../data/AReM/standing/dataset15.csv\n",
      "52 .   ../data/AReM/standing/dataset4.csv\n",
      "53 .   ../data/AReM/standing/dataset5.csv\n",
      "54 .   ../data/AReM/standing/dataset6.csv\n",
      "55 .   ../data/AReM/standing/dataset7.csv\n",
      "56 .   ../data/AReM/standing/dataset8.csv\n",
      "57 .   ../data/AReM/standing/dataset9.csv\n",
      "58 .   ../data/AReM/walking/dataset10.csv\n",
      "59 .   ../data/AReM/walking/dataset11.csv\n",
      "60 .   ../data/AReM/walking/dataset12.csv\n",
      "61 .   ../data/AReM/walking/dataset13.csv\n",
      "62 .   ../data/AReM/walking/dataset14.csv\n",
      "63 .   ../data/AReM/walking/dataset15.csv\n",
      "64 .   ../data/AReM/walking/dataset4.csv\n",
      "65 .   ../data/AReM/walking/dataset5.csv\n",
      "66 .   ../data/AReM/walking/dataset6.csv\n",
      "67 .   ../data/AReM/walking/dataset7.csv\n",
      "68 .   ../data/AReM/walking/dataset8.csv\n",
      "69 .   ../data/AReM/walking/dataset9.csv\n"
     ]
    }
   ],
   "source": [
    "# getting folder and files name. (preprocessing of data)\n",
    "\n",
    "total_folder=os.listdir('../data/AReM/')\n",
    "\n",
    "print(\"total folders:\",total_folder)\n",
    "\n",
    "#1.\n",
    "bending1_folder=os.listdir('../data/AReM/bending1')\n",
    "bending1_folder.sort()\n",
    "#print(\"bending 1 files: \",bending1_folder)\n",
    "\n",
    "#2.\n",
    "bending2_folder=os.listdir('../data/AReM/bending2')\n",
    "bending2_folder.sort()\n",
    "#print(\"bending 2 files: \",bending2_folder)\n",
    "\n",
    "#3.\n",
    "cycling_folder=os.listdir('../data/AReM/cycling')\n",
    "cycling_folder.sort()\n",
    "#print(\"cycling files: \",cycling_folder)\n",
    "\n",
    "\n",
    "#4.\n",
    "lying_folder=os.listdir('../data/AReM/lying')\n",
    "lying_folder.sort()\n",
    "#print(\"lying files: \",lying_folder)\n",
    "\n",
    "#5.\n",
    "sitting_folder=os.listdir('../data/AReM/sitting')\n",
    "sitting_folder.sort()\n",
    "#print(\"sitting files: \",sitting_folder)\n",
    "\n",
    "#6.\n",
    "standing_folder=os.listdir('../data/AReM/standing')\n",
    "standing_folder.sort()\n",
    "#print(\"standing files: \",standing_folder)\n",
    "\n",
    "#7.\n",
    "walking_folder=os.listdir('../data/AReM/walking')\n",
    "walking_folder.sort()\n",
    "#print(\"walking files: \",walking_folder)\n",
    "    \n",
    "all_paths=[]   ## 88 instances\n",
    "trainfile_paths=[] ## 69 instances\n",
    "testfile_paths=[] ## 19 instances\n",
    "\n",
    "# copy test data from bending1 and bending2: (dataset1,dataset2)\n",
    "\n",
    "for i,filename in enumerate(bending1_folder):\n",
    "    #print filename\n",
    "    if filename=='dataset1.csv' or filename=='dataset2.csv' :\n",
    "        all_paths.append('../data/AReM/bending1/'+filename)\n",
    "        testfile_paths.append('../data/AReM/bending1/'+filename)        \n",
    "        \n",
    "for i,filename in enumerate(bending2_folder):\n",
    "    if filename=='dataset1.csv' or filename=='dataset2.csv':\n",
    "        all_paths.append('../data/AReM/bending2/'+filename)\n",
    "        testfile_paths.append('../data/AReM/bending2/'+filename)\n",
    "        \n",
    "        \n",
    "for i,filename in enumerate(lying_folder):\n",
    "    if filename in ['dataset1.csv','dataset2.csv','dataset3.csv']:\n",
    "        all_paths.append('../data/AReM/lying/'+filename)\n",
    "        testfile_paths.append('../data/AReM/lying/'+filename)        \n",
    "\n",
    "for i,filename in enumerate(cycling_folder):\n",
    "    if filename in ['dataset1.csv','dataset2.csv','dataset3.csv']:\n",
    "        all_paths.append('../data/AReM/cycling/'+filename)\n",
    "        testfile_paths.append('../data/AReM/cycling/'+filename)        \n",
    "\n",
    "for i,filename in enumerate(sitting_folder):\n",
    "    if filename in ['dataset1.csv','dataset2.csv','dataset3.csv']:\n",
    "        all_paths.append('../data/AReM/sitting/'+filename)    \n",
    "        testfile_paths.append('../data/AReM/sitting/'+filename)        \n",
    "\n",
    "for i,filename in enumerate(standing_folder):\n",
    "    if filename in ['dataset1.csv','dataset2.csv','dataset3.csv']:\n",
    "        all_paths.append('../data/AReM/standing/'+filename) \n",
    "        testfile_paths.append('../data/AReM/standing/'+filename)        \n",
    "\n",
    "for i,filename in enumerate(walking_folder):\n",
    "    if filename in ['dataset1.csv','dataset2.csv','dataset3.csv']:\n",
    "        all_paths.append('../data/AReM/walking/'+filename) \n",
    "        testfile_paths.append('../data/AReM/walking/'+filename)          \n",
    "        \n",
    "               \n",
    "# extracting train data directories:\n",
    "\n",
    "bending1=['dataset3.csv','dataset4.csv','dataset5.csv','dataset6.csv','dataset7.csv']\n",
    "\n",
    "bending2=['dataset3.csv','dataset4.csv','dataset5.csv','dataset6.csv']\n",
    "\n",
    "others=['dataset4.csv','dataset5.csv','dataset6.csv','dataset7.csv','dataset8.csv','dataset9.csv',\n",
    "           'dataset10.csv','dataset11.csv','dataset12.csv','dataset13.csv','dataset14.csv','dataset15.csv']\n",
    "\n",
    "for i,filename in enumerate(bending1_folder):\n",
    "    if filename in bending1:\n",
    "        all_paths.append('../data/AReM/bending1/'+filename)\n",
    "        trainfile_paths.append('../data/AReM/bending1/'+filename)        \n",
    "\n",
    "for i,filename in enumerate(bending2_folder):\n",
    "    if filename in bending2:\n",
    "        all_paths.append('../data/AReM/bending2/'+filename)\n",
    "        trainfile_paths.append('../data/AReM/bending2/'+filename)        \n",
    "\n",
    "for i,filename in enumerate(lying_folder):\n",
    "    if filename in others:\n",
    "        all_paths.append('../data/AReM/lying/'+filename) \n",
    "        trainfile_paths.append('../data/AReM/lying/'+filename)         \n",
    "\n",
    "for i,filename in enumerate(cycling_folder):\n",
    "    if filename in others:\n",
    "        all_paths.append('../data/AReM/cycling/'+filename) \n",
    "        trainfile_paths.append('../data/AReM/cycling/'+filename)         \n",
    "\n",
    "for i,filename in enumerate(sitting_folder):\n",
    "    if filename in others:\n",
    "        all_paths.append('../data/AReM/sitting/'+filename) \n",
    "        trainfile_paths.append('../data/AReM/sitting/'+filename)         \n",
    "\n",
    "for i,filename in enumerate(standing_folder):\n",
    "    if filename in others:\n",
    "        all_paths.append('../data/AReM/standing/'+filename)\n",
    "        trainfile_paths.append('../data/AReM/standing/'+filename)         \n",
    "\n",
    "for i,filename in enumerate(walking_folder):\n",
    "    if filename in others:\n",
    "        all_paths.append('../data/AReM/walking/'+filename)\n",
    "        trainfile_paths.append('../data/AReM/walking/'+filename)   \n",
    "        \n",
    "#print((trainfile_paths))\n",
    "\n",
    "print(\"Total Instances: \",len(all_paths))\n",
    "print(\"Training Instances: \",len(trainfile_paths))\n",
    "print(\"Testing Instances: \",len(testfile_paths))\n",
    "\n",
    "print(\"Each Data File has 480 rows and 6 time-series columns\\n\")\n",
    "print('six time series features --\\n 1. avg_rss12\\n','2. var_rss12\\n','3. avg_rss13\\n','4. var_rss13\\n','5. avg_rss23\\n','6. var_rss23\\n')\n",
    "\n",
    "\n",
    "print(\"\\n ------ All file paths: \",len(all_paths),\" Instances \\n\")\n",
    "i=0\n",
    "for paths in all_paths:\n",
    "    print((i+1),\". \",paths)\n",
    "    i=i+1\n",
    "\n",
    "i=0\n",
    "print(\"\\n ------- Total test files: \",len(testfile_paths),\"Instances \\n\")\n",
    "for files in testfile_paths:\n",
    "        print(i+1,\".  \",files)\n",
    "        i=i+1\n",
    " \n",
    "i=0\n",
    "print(\"\\n ------- Total train files: \",len(trainfile_paths),\"Instances \\n\")\n",
    "for files in trainfile_paths:\n",
    "        print(i+1,\".  \",files)\n",
    "        i=i+1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- COMPLETE DATA -----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42234</th>\n",
       "      <td>118750</td>\n",
       "      <td>31.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>12.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4.44</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42235</th>\n",
       "      <td>119000</td>\n",
       "      <td>27.33</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>20.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42236</th>\n",
       "      <td>119250</td>\n",
       "      <td>37.80</td>\n",
       "      <td>7.68</td>\n",
       "      <td>14.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42237</th>\n",
       "      <td>119500</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "      <td>15.75</td>\n",
       "      <td>5.21</td>\n",
       "      <td>16.50</td>\n",
       "      <td>2.69</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42238</th>\n",
       "      <td>119750</td>\n",
       "      <td>32.67</td>\n",
       "      <td>3.09</td>\n",
       "      <td>18.67</td>\n",
       "      <td>0.47</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42239 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
       "0           0      39.25       0.43      22.75       0.43      33.75   \n",
       "1         250      39.25       0.43      23.00       0.00      33.00   \n",
       "2         500      39.25       0.43      23.25       0.43      33.00   \n",
       "3         750      39.50       0.50      23.00       0.71      33.00   \n",
       "4        1000      39.50       0.50      24.00       0.00      33.00   \n",
       "...       ...        ...        ...        ...        ...        ...   \n",
       "42234  118750      31.50       1.66      12.50       3.20      14.25   \n",
       "42235  119000      27.33       1.25      11.33       0.94      20.00   \n",
       "42236  119250      37.80       7.68      14.20       2.48      17.25   \n",
       "42237  119500      33.75       1.30      15.75       5.21      16.50   \n",
       "42238  119750      32.67       3.09      18.67       0.47      14.00   \n",
       "\n",
       "       var_rss23 activity  \n",
       "0           1.30    bend1  \n",
       "1           0.00    bend1  \n",
       "2           0.00    bend1  \n",
       "3           0.00    bend1  \n",
       "4           0.00    bend1  \n",
       "...          ...      ...  \n",
       "42234       4.44     walk  \n",
       "42235       4.00     walk  \n",
       "42236       0.83     walk  \n",
       "42237       2.69     walk  \n",
       "42238       3.16     walk  \n",
       "\n",
       "[42239 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking all data in data frame\n",
    "\n",
    "def complete_data(all_paths):\n",
    "    data=dict()\n",
    "\n",
    "    for i in range(0,len(all_paths),1):\n",
    "        data[i]=0\n",
    "        \n",
    "    name=''\n",
    "    for i,files in enumerate(all_paths):\n",
    "        \n",
    "        df=pd.read_csv(files, sep=' |,', names=['time','avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23'], skiprows=5,usecols=range(7),engine='python')   \n",
    "        #print(df)  \n",
    "        if(files[13:21]=='bending1'):\n",
    "            name='bend1'\n",
    "        elif(files[13:21]=='bending2'):\n",
    "            name='bend2'\n",
    "        else:\n",
    "            name=files[13:17] \n",
    "        df.loc[:,'activity'] = name\n",
    "        data[i]=df\n",
    "\n",
    "    # training_data\n",
    "    df_alldata=pd.DataFrame()\n",
    "    df_alldata=data[0]\n",
    "    for i in range(1,88,1):\n",
    "        df2=data[i]\n",
    "        df_alldata=pd.concat([df_alldata,df2], ignore_index=True)\n",
    "    return df_alldata\n",
    "    \n",
    "\n",
    "df_alldata=complete_data(all_paths)\n",
    "\n",
    "print(\"\\n-------- COMPLETE DATA -----\\n\")\n",
    "df_alldata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/AReM/sitting/dataset8.csv\n",
      "\n",
      "--------TRAINING DATA -----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>21.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>41.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20.25</td>\n",
       "      <td>1.48</td>\n",
       "      <td>31.25</td>\n",
       "      <td>1.09</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>41.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>14.25</td>\n",
       "      <td>1.92</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>40.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>15.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2.74</td>\n",
       "      <td>32.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33114</th>\n",
       "      <td>118750</td>\n",
       "      <td>31.50</td>\n",
       "      <td>1.66</td>\n",
       "      <td>12.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4.44</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33115</th>\n",
       "      <td>119000</td>\n",
       "      <td>27.33</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>20.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33116</th>\n",
       "      <td>119250</td>\n",
       "      <td>37.80</td>\n",
       "      <td>7.68</td>\n",
       "      <td>14.20</td>\n",
       "      <td>2.48</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33117</th>\n",
       "      <td>119500</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "      <td>15.75</td>\n",
       "      <td>5.21</td>\n",
       "      <td>16.50</td>\n",
       "      <td>2.69</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33118</th>\n",
       "      <td>119750</td>\n",
       "      <td>32.67</td>\n",
       "      <td>3.09</td>\n",
       "      <td>18.67</td>\n",
       "      <td>0.47</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3.16</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33119 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
       "0           0      42.00       0.71      21.25       0.43      30.00   \n",
       "1         250      41.50       0.50      20.25       1.48      31.25   \n",
       "2         500      41.50       0.50      14.25       1.92      33.00   \n",
       "3         750      40.75       0.83      15.75       0.43      33.00   \n",
       "4        1000      40.00       0.71      20.00       2.74      32.75   \n",
       "...       ...        ...        ...        ...        ...        ...   \n",
       "33114  118750      31.50       1.66      12.50       3.20      14.25   \n",
       "33115  119000      27.33       1.25      11.33       0.94      20.00   \n",
       "33116  119250      37.80       7.68      14.20       2.48      17.25   \n",
       "33117  119500      33.75       1.30      15.75       5.21      16.50   \n",
       "33118  119750      32.67       3.09      18.67       0.47      14.00   \n",
       "\n",
       "       var_rss23 activity  \n",
       "0           0.00    bend1  \n",
       "1           1.09    bend1  \n",
       "2           0.00    bend1  \n",
       "3           0.00    bend1  \n",
       "4           0.43    bend1  \n",
       "...          ...      ...  \n",
       "33114       4.44     walk  \n",
       "33115       4.00     walk  \n",
       "33116       0.83     walk  \n",
       "33117       2.69     walk  \n",
       "33118       3.16     walk  \n",
       "\n",
       "[33119 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train Data\n",
    "\n",
    "def training_datacombined(trainfile_paths):\n",
    "    training_data=dict()\n",
    "\n",
    "    for i in range(0,len(trainfile_paths),1):\n",
    "        training_data[i]=0\n",
    "    \n",
    "    name=''\n",
    "\n",
    "    for i,files in enumerate(trainfile_paths):\n",
    "        #df=pd.read_csv(files)\n",
    "        df=pd.read_csv(files, sep=' |,', names=['time','avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23'], skiprows=5,usecols=range(7),engine='python')\n",
    "        \n",
    "        if len(df)!=480 :\n",
    "            print(files)\n",
    "        \n",
    "        if(files[13:21]=='bending1'):\n",
    "            name='bend1'\n",
    "        elif(files[13:21]=='bending2'):\n",
    "            name='bend2'\n",
    "        else:\n",
    "            name=files[13:17] \n",
    "        df.loc[:,'activity'] = name\n",
    "        training_data[i]=df\n",
    "\n",
    "    # training_data\n",
    "    df_traindata=pd.DataFrame()\n",
    "   \n",
    "    df_traindata=training_data[0]\n",
    "    #print(df_traindata)\n",
    "    for i in range(1,69,1):\n",
    "        df2=training_data[i]\n",
    "        df_traindata=pd.concat([df_traindata,df2], ignore_index=True)\n",
    "\n",
    "    return df_traindata\n",
    "\n",
    "\n",
    "df_traindata=training_datacombined(trainfile_paths)\n",
    "    \n",
    "print(\"\\n--------TRAINING DATA -----\\n\")\n",
    "df_traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------TESTING DATA -----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.75</td>\n",
       "      <td>1.30</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>39.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>23.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>39.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bend1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>118750</td>\n",
       "      <td>36.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>17.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.87</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>119000</td>\n",
       "      <td>34.33</td>\n",
       "      <td>1.89</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>119250</td>\n",
       "      <td>33.00</td>\n",
       "      <td>7.35</td>\n",
       "      <td>14.60</td>\n",
       "      <td>3.14</td>\n",
       "      <td>13.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>119500</td>\n",
       "      <td>31.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.16</td>\n",
       "      <td>19.25</td>\n",
       "      <td>2.17</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>119750</td>\n",
       "      <td>30.75</td>\n",
       "      <td>10.21</td>\n",
       "      <td>11.75</td>\n",
       "      <td>1.09</td>\n",
       "      <td>18.50</td>\n",
       "      <td>3.20</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
       "0          0      39.25       0.43      22.75       0.43      33.75   \n",
       "1        250      39.25       0.43      23.00       0.00      33.00   \n",
       "2        500      39.25       0.43      23.25       0.43      33.00   \n",
       "3        750      39.50       0.50      23.00       0.71      33.00   \n",
       "4       1000      39.50       0.50      24.00       0.00      33.00   \n",
       "...      ...        ...        ...        ...        ...        ...   \n",
       "9115  118750      36.00       2.45      17.00       5.10      20.50   \n",
       "9116  119000      34.33       1.89      15.00       2.45      17.00   \n",
       "9117  119250      33.00       7.35      14.60       3.14      13.00   \n",
       "9118  119500      31.67       1.25      11.00       6.16      19.25   \n",
       "9119  119750      30.75      10.21      11.75       1.09      18.50   \n",
       "\n",
       "      var_rss23 activity  \n",
       "0          1.30    bend1  \n",
       "1          0.00    bend1  \n",
       "2          0.00    bend1  \n",
       "3          0.00    bend1  \n",
       "4          0.00    bend1  \n",
       "...         ...      ...  \n",
       "9115       0.87     walk  \n",
       "9116       2.12     walk  \n",
       "9117       5.70     walk  \n",
       "9118       2.17     walk  \n",
       "9119       3.20     walk  \n",
       "\n",
       "[9120 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test  data\n",
    "def testing_datacombined(testfile_paths):\n",
    "    testing_data=dict()\n",
    "\n",
    "    for i in range(0,len(testfile_paths),1):\n",
    "        testing_data[i]=0\n",
    "        \n",
    "    name=''\n",
    "\n",
    "    for i,files in enumerate(testfile_paths):\n",
    "        \n",
    "        df=pd.read_csv(files, sep=' |,', names=['time','avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23'], skiprows=5,usecols=range(7),engine='python')\n",
    "    \n",
    "        if(files[13:21]=='bending1'):\n",
    "            name='bend1'\n",
    "        elif(files[13:21]=='bending2'):\n",
    "            name='bend2'\n",
    "        else:\n",
    "            name=files[13:17] \n",
    "        df.loc[:,'activity'] = name\n",
    "        testing_data[i]=df\n",
    "\n",
    "\n",
    "    df_testdata=pd.DataFrame()\n",
    "    df_testdata=testing_data[0]\n",
    "    for i in range(1,19,1):\n",
    "        df2=testing_data[i]\n",
    "        df_testdata=pd.concat([df_testdata,df2], ignore_index=True)\n",
    "        \n",
    "    return df_testdata\n",
    "\n",
    "\n",
    "df_testdata=testing_datacombined(testfile_paths)\n",
    "\n",
    "print(\"\\n--------TESTING DATA -----\\n\")\n",
    "df_testdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "1. Statistical Features: <br>\n",
    "    a. Mean  <br>\n",
    "    b. Median <br>\n",
    "    c. Standard Deviation <br>\n",
    "    d. Skewness, Kurtosis <br>\n",
    "    e. Minimum and Maximum\n",
    "    f. Quantiles(25th,75th and Interquartile ranges\n",
    "<br><br>\n",
    "2. Time Series Analysis Related Features: <br>\n",
    "    a. Cross Correlation <br>\n",
    "    b. Auto Correlation <br>\n",
    "    c. Parameters of Autoregressive (AR) part of Autoregressive Integrated Moving Average (ARIMA) model <br>\n",
    "    d. Parameters of Moving Average (MA) part of ARIMA model <br>\n",
    "    e. Orders of AR, Integrated (I) and MA part of ARIMA model  \n",
    "<br><br>\n",
    "3. Frequency domain related features: <br>\n",
    "    a. Frequencies of the k peaks in amplitude in the DFTs (discrete Fourier transform) for the detrended d dimensions<br>\n",
    "    b. k-quantiles of these DFTs.<br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All instances:\n",
      "1 .  ../data/AReM/bending1/dataset1.csv\n",
      "2 .  ../data/AReM/bending1/dataset2.csv\n",
      "3 .  ../data/AReM/bending2/dataset1.csv\n",
      "4 .  ../data/AReM/bending2/dataset2.csv\n",
      "5 .  ../data/AReM/lying/dataset1.csv\n",
      "6 .  ../data/AReM/lying/dataset2.csv\n",
      "7 .  ../data/AReM/lying/dataset3.csv\n",
      "8 .  ../data/AReM/cycling/dataset1.csv\n",
      "9 .  ../data/AReM/cycling/dataset2.csv\n",
      "10 .  ../data/AReM/cycling/dataset3.csv\n",
      "11 .  ../data/AReM/sitting/dataset1.csv\n",
      "12 .  ../data/AReM/sitting/dataset2.csv\n",
      "13 .  ../data/AReM/sitting/dataset3.csv\n",
      "14 .  ../data/AReM/standing/dataset1.csv\n",
      "15 .  ../data/AReM/standing/dataset2.csv\n",
      "16 .  ../data/AReM/standing/dataset3.csv\n",
      "17 .  ../data/AReM/walking/dataset1.csv\n",
      "18 .  ../data/AReM/walking/dataset2.csv\n",
      "19 .  ../data/AReM/walking/dataset3.csv\n",
      "20 .  ../data/AReM/bending1/dataset3.csv\n",
      "21 .  ../data/AReM/bending1/dataset4.csv\n",
      "22 .  ../data/AReM/bending1/dataset5.csv\n",
      "23 .  ../data/AReM/bending1/dataset6.csv\n",
      "24 .  ../data/AReM/bending1/dataset7.csv\n",
      "25 .  ../data/AReM/bending2/dataset3.csv\n",
      "26 .  ../data/AReM/bending2/dataset4.csv\n",
      "27 .  ../data/AReM/bending2/dataset5.csv\n",
      "28 .  ../data/AReM/bending2/dataset6.csv\n",
      "29 .  ../data/AReM/lying/dataset10.csv\n",
      "30 .  ../data/AReM/lying/dataset11.csv\n",
      "31 .  ../data/AReM/lying/dataset12.csv\n",
      "32 .  ../data/AReM/lying/dataset13.csv\n",
      "33 .  ../data/AReM/lying/dataset14.csv\n",
      "34 .  ../data/AReM/lying/dataset15.csv\n",
      "35 .  ../data/AReM/lying/dataset4.csv\n",
      "36 .  ../data/AReM/lying/dataset5.csv\n",
      "37 .  ../data/AReM/lying/dataset6.csv\n",
      "38 .  ../data/AReM/lying/dataset7.csv\n",
      "39 .  ../data/AReM/lying/dataset8.csv\n",
      "40 .  ../data/AReM/lying/dataset9.csv\n",
      "41 .  ../data/AReM/cycling/dataset10.csv\n",
      "42 .  ../data/AReM/cycling/dataset11.csv\n",
      "43 .  ../data/AReM/cycling/dataset12.csv\n",
      "44 .  ../data/AReM/cycling/dataset13.csv\n",
      "45 .  ../data/AReM/cycling/dataset14.csv\n",
      "46 .  ../data/AReM/cycling/dataset15.csv\n",
      "47 .  ../data/AReM/cycling/dataset4.csv\n",
      "48 .  ../data/AReM/cycling/dataset5.csv\n",
      "49 .  ../data/AReM/cycling/dataset6.csv\n",
      "50 .  ../data/AReM/cycling/dataset7.csv\n",
      "51 .  ../data/AReM/cycling/dataset8.csv\n",
      "52 .  ../data/AReM/cycling/dataset9.csv\n",
      "53 .  ../data/AReM/sitting/dataset10.csv\n",
      "54 .  ../data/AReM/sitting/dataset11.csv\n",
      "55 .  ../data/AReM/sitting/dataset12.csv\n",
      "56 .  ../data/AReM/sitting/dataset13.csv\n",
      "57 .  ../data/AReM/sitting/dataset14.csv\n",
      "58 .  ../data/AReM/sitting/dataset15.csv\n",
      "59 .  ../data/AReM/sitting/dataset4.csv\n",
      "60 .  ../data/AReM/sitting/dataset5.csv\n",
      "61 .  ../data/AReM/sitting/dataset6.csv\n",
      "62 .  ../data/AReM/sitting/dataset7.csv\n",
      "63 .  ../data/AReM/sitting/dataset8.csv\n",
      "64 .  ../data/AReM/sitting/dataset9.csv\n",
      "65 .  ../data/AReM/standing/dataset10.csv\n",
      "66 .  ../data/AReM/standing/dataset11.csv\n",
      "67 .  ../data/AReM/standing/dataset12.csv\n",
      "68 .  ../data/AReM/standing/dataset13.csv\n",
      "69 .  ../data/AReM/standing/dataset14.csv\n",
      "70 .  ../data/AReM/standing/dataset15.csv\n",
      "71 .  ../data/AReM/standing/dataset4.csv\n",
      "72 .  ../data/AReM/standing/dataset5.csv\n",
      "73 .  ../data/AReM/standing/dataset6.csv\n",
      "74 .  ../data/AReM/standing/dataset7.csv\n",
      "75 .  ../data/AReM/standing/dataset8.csv\n",
      "76 .  ../data/AReM/standing/dataset9.csv\n",
      "77 .  ../data/AReM/walking/dataset10.csv\n",
      "78 .  ../data/AReM/walking/dataset11.csv\n",
      "79 .  ../data/AReM/walking/dataset12.csv\n",
      "80 .  ../data/AReM/walking/dataset13.csv\n",
      "81 .  ../data/AReM/walking/dataset14.csv\n",
      "82 .  ../data/AReM/walking/dataset15.csv\n",
      "83 .  ../data/AReM/walking/dataset4.csv\n",
      "84 .  ../data/AReM/walking/dataset5.csv\n",
      "85 .  ../data/AReM/walking/dataset6.csv\n",
      "86 .  ../data/AReM/walking/dataset7.csv\n",
      "87 .  ../data/AReM/walking/dataset8.csv\n",
      "88 .  ../data/AReM/walking/dataset9.csv\n",
      "\n",
      "Time domain features of all the data: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12_max</th>\n",
       "      <th>avg_rss12_min</th>\n",
       "      <th>avg_rss12_mean</th>\n",
       "      <th>avg_rss12_median</th>\n",
       "      <th>avg_rss12_std</th>\n",
       "      <th>avg_rss12_quart25</th>\n",
       "      <th>avg_rss12_quart75</th>\n",
       "      <th>var_rss12_max</th>\n",
       "      <th>var_rss12_min</th>\n",
       "      <th>var_rss12_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_rss23_std</th>\n",
       "      <th>avg_rss23_quart25</th>\n",
       "      <th>avg_rss23_quart75</th>\n",
       "      <th>var_rss23_max</th>\n",
       "      <th>var_rss23_min</th>\n",
       "      <th>var_rss23_mean</th>\n",
       "      <th>var_rss23_median</th>\n",
       "      <th>var_rss23_std</th>\n",
       "      <th>var_rss23_quart25</th>\n",
       "      <th>var_rss23_quart75</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>37.25</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.5</td>\n",
       "      <td>1.476967</td>\n",
       "      <td>39.25</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188449</td>\n",
       "      <td>33.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.67</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.812812</td>\n",
       "      <td>42.5</td>\n",
       "      <td>1.43555</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372438</td>\n",
       "      <td>...</td>\n",
       "      <td>1.995255</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.60101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>24.562958</td>\n",
       "      <td>24.25</td>\n",
       "      <td>3.737514</td>\n",
       "      <td>23.1875</td>\n",
       "      <td>26.5</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590833</td>\n",
       "      <td>...</td>\n",
       "      <td>3.693786</td>\n",
       "      <td>20.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700188</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.69372</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.464604</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.583582</td>\n",
       "      <td>25.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449708</td>\n",
       "      <td>...</td>\n",
       "      <td>5.053642</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>6.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.122125</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.012342</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>27.716375</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.442253</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363688</td>\n",
       "      <td>...</td>\n",
       "      <td>4.074511</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.75</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734271</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.613688</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>46.25</td>\n",
       "      <td>20.75</td>\n",
       "      <td>34.763333</td>\n",
       "      <td>35.29</td>\n",
       "      <td>4.742208</td>\n",
       "      <td>31.67</td>\n",
       "      <td>38.25</td>\n",
       "      <td>12.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.223792</td>\n",
       "      <td>...</td>\n",
       "      <td>3.174681</td>\n",
       "      <td>14.25</td>\n",
       "      <td>18.33</td>\n",
       "      <td>9.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.288271</td>\n",
       "      <td>3.27</td>\n",
       "      <td>1.647528</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>34.935813</td>\n",
       "      <td>35.5</td>\n",
       "      <td>4.645944</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0625</td>\n",
       "      <td>12.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.11575</td>\n",
       "      <td>...</td>\n",
       "      <td>3.192058</td>\n",
       "      <td>14.2375</td>\n",
       "      <td>18.25</td>\n",
       "      <td>10.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.280021</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.700918</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>47.67</td>\n",
       "      <td>18.33</td>\n",
       "      <td>34.333042</td>\n",
       "      <td>34.75</td>\n",
       "      <td>4.94877</td>\n",
       "      <td>31.25</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.396958</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000493</td>\n",
       "      <td>13.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.261583</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.61729</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>45.75</td>\n",
       "      <td>18.33</td>\n",
       "      <td>34.599875</td>\n",
       "      <td>35.125</td>\n",
       "      <td>4.73179</td>\n",
       "      <td>31.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.398833</td>\n",
       "      <td>...</td>\n",
       "      <td>2.905688</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.25</td>\n",
       "      <td>8.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.289542</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.68017</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>43.67</td>\n",
       "      <td>15.5</td>\n",
       "      <td>34.225875</td>\n",
       "      <td>34.75</td>\n",
       "      <td>4.441798</td>\n",
       "      <td>31.25</td>\n",
       "      <td>37.25</td>\n",
       "      <td>17.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3545</td>\n",
       "      <td>...</td>\n",
       "      <td>2.99292</td>\n",
       "      <td>14.33</td>\n",
       "      <td>18.25</td>\n",
       "      <td>9.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.479542</td>\n",
       "      <td>3.27</td>\n",
       "      <td>1.761146</td>\n",
       "      <td>2.24</td>\n",
       "      <td>4.5375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rss12_max avg_rss12_min avg_rss12_mean avg_rss12_median  \\\n",
       "instance                                                               \n",
       "1                 45.0         37.25      40.624792             40.5   \n",
       "2                45.67          38.0      42.812812             42.5   \n",
       "3                 51.0         12.75      24.562958            24.25   \n",
       "4                42.75           0.0      27.464604             28.0   \n",
       "5                 30.0          23.5      27.716375             27.5   \n",
       "...                ...           ...            ...              ...   \n",
       "84               46.25         20.75      34.763333            35.29   \n",
       "85                51.0          21.5      34.935813             35.5   \n",
       "86               47.67         18.33      34.333042            34.75   \n",
       "87               45.75         18.33      34.599875           35.125   \n",
       "88               43.67          15.5      34.225875            34.75   \n",
       "\n",
       "         avg_rss12_std avg_rss12_quart25 avg_rss12_quart75 var_rss12_max  \\\n",
       "instance                                                                   \n",
       "1             1.476967             39.25              42.0           1.3   \n",
       "2              1.43555              42.0             43.67          1.22   \n",
       "3             3.737514           23.1875              26.5          6.87   \n",
       "4             3.583582              25.5              30.0          7.76   \n",
       "5             1.442253              27.0              29.0          1.79   \n",
       "...                ...               ...               ...           ...   \n",
       "84            4.742208             31.67             38.25         12.68   \n",
       "85            4.645944              32.0           38.0625         12.21   \n",
       "86             4.94877             31.25              38.0         12.48   \n",
       "87             4.73179              31.5              38.0         15.37   \n",
       "88            4.441798             31.25             37.25         17.24   \n",
       "\n",
       "         var_rss12_min var_rss12_mean  ... avg_rss23_std avg_rss23_quart25  \\\n",
       "instance                               ...                                   \n",
       "1                  0.0       0.358604  ...      2.188449              33.0   \n",
       "2                  0.0       0.372438  ...      1.995255              32.0   \n",
       "3                  0.0       0.590833  ...      3.693786              20.5   \n",
       "4                  0.0       0.449708  ...      5.053642              15.0   \n",
       "5                  0.0       0.363688  ...      4.074511               5.5   \n",
       "...                ...            ...  ...           ...               ...   \n",
       "84                 0.0       4.223792  ...      3.174681             14.25   \n",
       "85                 0.0        4.11575  ...      3.192058           14.2375   \n",
       "86                 0.0       4.396958  ...      3.000493             13.75   \n",
       "87                 0.0       4.398833  ...      2.905688              14.0   \n",
       "88                 0.0         4.3545  ...       2.99292             14.33   \n",
       "\n",
       "         avg_rss23_quart75 var_rss23_max var_rss23_min var_rss23_mean  \\\n",
       "instance                                                                \n",
       "1                     36.0          1.92           0.0       0.570583   \n",
       "2                     34.5          3.11           0.0       0.571083   \n",
       "3                     27.0          4.97           0.0       0.700188   \n",
       "4                    20.75          6.76           0.0       1.122125   \n",
       "5                    10.75           4.5           0.0       0.734271   \n",
       "...                    ...           ...           ...            ...   \n",
       "84                   18.33          9.39           0.0       3.288271   \n",
       "85                   18.25         10.21           0.0       3.280021   \n",
       "86                    18.0          8.01           0.0       3.261583   \n",
       "87                   18.25          8.86           0.0       3.289542   \n",
       "88                   18.25          9.42           0.0       3.479542   \n",
       "\n",
       "         var_rss23_median var_rss23_std var_rss23_quart25 var_rss23_quart75  \n",
       "instance                                                                     \n",
       "1                    0.43      0.582915               0.0               1.3  \n",
       "2                    0.43       0.60101               0.0               1.3  \n",
       "3                     0.5       0.69372              0.43              0.87  \n",
       "4                    0.83      1.012342              0.47               1.3  \n",
       "5                    0.71      0.613688              0.43               1.0  \n",
       "...                   ...           ...               ...               ...  \n",
       "84                   3.27      1.647528              2.05             4.305  \n",
       "85                  3.015      1.700918              2.12               4.5  \n",
       "86                   2.98       1.61729              2.05              4.32  \n",
       "87                  3.015       1.68017              2.12              4.26  \n",
       "88                   3.27      1.761146              2.24            4.5375  \n",
       "\n",
       "[88 rows x 42 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ii. Extract the time-domain features minimum, maximum, mean, median, standard deviation, first quartile, and third quartile for all of the 6 time series\n",
    "in each instance. You are free to normalize/standardize features or use them\n",
    "directly.2\n",
    "'''\n",
    "\n",
    "table_columns=['avg_rss12_max', 'avg_rss12_min','avg_rss12_mean','avg_rss12_median','avg_rss12_std','avg_rss12_quart25','avg_rss12_quart75',\n",
    "            'var_rss12_max', 'var_rss12_min','var_rss12_mean','var_rss12_median','var_rss12_stdt','var_rss12_quart25','var_rss12_quart75',\n",
    "            'avg_rss13_max', 'avg_rss13_min','avg_rss13_mean','avg_rss13_median','avg_rss13_std','avg_rss13_quart25','avg_rss13_quart75',\n",
    "            'var_rss13_max', 'var_rss13_min','var_rss13_mean','var_rss13_median','var_rss13_std','var_rss13_quart25','var_rss13_quart75',\n",
    "            'avg_rss23_max', 'avg_rss23_min','avg_rss23_mean','avg_rss23_median','avg_rss23_std','avg_rss23_quart25','avg_rss23_quart75',\n",
    "            'var_rss23_max', 'var_rss23_min','var_rss23_mean','var_rss23_median','var_rss23_std','var_rss23_quart25','var_rss23_quart75']\n",
    "\n",
    "\n",
    "time_feature_table = pd.DataFrame(columns=table_columns)\n",
    "\n",
    "\n",
    "\n",
    "df_col_names=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "\n",
    "temp=[]\n",
    "\n",
    "print(\"\\n All instances:\")\n",
    "num=1\n",
    "for rowid,paths in enumerate(all_paths):\n",
    "      \n",
    "    print (num,\". \",paths)\n",
    "    num=num+1\n",
    "    df=pd.read_csv(paths, sep=' |,', names=['time','avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23'], skiprows=5,usecols=range(7),engine='python')\n",
    "    \n",
    "    for col in df_col_names:\n",
    "        \n",
    "        #maximum\n",
    "        ts_max=df[col].max()\n",
    "        temp.append(ts_max)\n",
    "\n",
    "        #minimum\n",
    "        ts_min=df[col].min()\n",
    "        temp.append(ts_min)\n",
    "\n",
    "        #mean\n",
    "        ts_mean=df[col].mean()\n",
    "        temp.append(ts_mean)\n",
    "\n",
    "        #median\n",
    "        ts_median=df[col].median()\n",
    "        temp.append(ts_median)\n",
    "\n",
    "        #standard deviation\n",
    "        ts_std=df[col].std()\n",
    "        temp.append(ts_std)\n",
    "\n",
    "        #first quartile\n",
    "        ts_quant1=df[col].quantile(0.25)\n",
    "        temp.append(ts_quant1)\n",
    "\n",
    "        #third quartile\n",
    "        ts_quant3=df[col].quantile(0.75)\n",
    "        temp.append(ts_quant3)\n",
    "            \n",
    "    for l,m in enumerate(table_columns):\n",
    "        time_feature_table.at[rowid,m]=temp[l]\n",
    "        \n",
    "    temp=[]\n",
    "    \n",
    "\n",
    "print(\"\\nTime domain features of all the data: \\n\")\n",
    "\n",
    "time_feature_table.index = np.arange(1, len(time_feature_table) + 1)\n",
    "time_feature_table.index.name='instance'\n",
    "time_feature_table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated Standard Deviation and their 90% bootsrap confidence interval (CI) for the standard deviation of each feature\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STD_Deviation</th>\n",
       "      <th>CI_value</th>\n",
       "      <th>CI_Lower_Bound</th>\n",
       "      <th>CI_Upper_Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_rss12_max</th>\n",
       "      <td>4.394362</td>\n",
       "      <td>4.369322</td>\n",
       "      <td>3.478739</td>\n",
       "      <td>5.412790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss12_min</th>\n",
       "      <td>9.569975</td>\n",
       "      <td>9.515445</td>\n",
       "      <td>8.300624</td>\n",
       "      <td>10.808411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss12_mean</th>\n",
       "      <td>5.335718</td>\n",
       "      <td>5.305314</td>\n",
       "      <td>4.759450</td>\n",
       "      <td>5.920412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss12_median</th>\n",
       "      <td>5.440054</td>\n",
       "      <td>5.409056</td>\n",
       "      <td>4.845730</td>\n",
       "      <td>6.061634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss12_std</th>\n",
       "      <td>1.772153</td>\n",
       "      <td>1.762056</td>\n",
       "      <td>1.586343</td>\n",
       "      <td>1.961788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss12_quart25</th>\n",
       "      <td>6.153590</td>\n",
       "      <td>6.118526</td>\n",
       "      <td>5.627331</td>\n",
       "      <td>6.700252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss12_quart75</th>\n",
       "      <td>5.138925</td>\n",
       "      <td>5.109643</td>\n",
       "      <td>4.410991</td>\n",
       "      <td>5.913547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss12_max</th>\n",
       "      <td>5.062729</td>\n",
       "      <td>5.033882</td>\n",
       "      <td>4.688412</td>\n",
       "      <td>5.476467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss12_min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss12_mean</th>\n",
       "      <td>1.574164</td>\n",
       "      <td>1.565194</td>\n",
       "      <td>1.432934</td>\n",
       "      <td>1.743668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss12_median</th>\n",
       "      <td>1.412244</td>\n",
       "      <td>1.404197</td>\n",
       "      <td>1.271341</td>\n",
       "      <td>1.575169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss12_stdt</th>\n",
       "      <td>0.884105</td>\n",
       "      <td>0.879068</td>\n",
       "      <td>0.822445</td>\n",
       "      <td>0.958607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss12_quart25</th>\n",
       "      <td>0.946386</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.852758</td>\n",
       "      <td>1.055922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss12_quart75</th>\n",
       "      <td>2.125266</td>\n",
       "      <td>2.113157</td>\n",
       "      <td>1.941150</td>\n",
       "      <td>2.342372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss13_max</th>\n",
       "      <td>4.875137</td>\n",
       "      <td>4.847358</td>\n",
       "      <td>4.263871</td>\n",
       "      <td>5.545271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss13_min</th>\n",
       "      <td>2.956462</td>\n",
       "      <td>2.939616</td>\n",
       "      <td>2.787780</td>\n",
       "      <td>3.132728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss13_mean</th>\n",
       "      <td>4.008380</td>\n",
       "      <td>3.985540</td>\n",
       "      <td>3.512224</td>\n",
       "      <td>4.576050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss13_median</th>\n",
       "      <td>4.036396</td>\n",
       "      <td>4.013397</td>\n",
       "      <td>3.519310</td>\n",
       "      <td>4.609368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss13_std</th>\n",
       "      <td>0.946710</td>\n",
       "      <td>0.941316</td>\n",
       "      <td>0.768252</td>\n",
       "      <td>1.125151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss13_quart25</th>\n",
       "      <td>4.220658</td>\n",
       "      <td>4.196608</td>\n",
       "      <td>3.725250</td>\n",
       "      <td>4.796682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss13_quart75</th>\n",
       "      <td>4.171628</td>\n",
       "      <td>4.147858</td>\n",
       "      <td>3.628029</td>\n",
       "      <td>4.772442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss13_max</th>\n",
       "      <td>2.183625</td>\n",
       "      <td>2.171183</td>\n",
       "      <td>1.994477</td>\n",
       "      <td>2.379343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss13_min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss13_mean</th>\n",
       "      <td>1.166114</td>\n",
       "      <td>1.159470</td>\n",
       "      <td>1.104503</td>\n",
       "      <td>1.252509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss13_median</th>\n",
       "      <td>1.145586</td>\n",
       "      <td>1.139058</td>\n",
       "      <td>1.083690</td>\n",
       "      <td>1.229823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss13_std</th>\n",
       "      <td>0.458242</td>\n",
       "      <td>0.455631</td>\n",
       "      <td>0.428047</td>\n",
       "      <td>0.491386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss13_quart25</th>\n",
       "      <td>0.843620</td>\n",
       "      <td>0.838813</td>\n",
       "      <td>0.791059</td>\n",
       "      <td>0.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss13_quart75</th>\n",
       "      <td>1.552504</td>\n",
       "      <td>1.543658</td>\n",
       "      <td>1.468470</td>\n",
       "      <td>1.666061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss23_max</th>\n",
       "      <td>5.741238</td>\n",
       "      <td>5.708524</td>\n",
       "      <td>4.905496</td>\n",
       "      <td>6.688121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss23_min</th>\n",
       "      <td>6.124001</td>\n",
       "      <td>6.089107</td>\n",
       "      <td>4.717083</td>\n",
       "      <td>7.794325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss23_mean</th>\n",
       "      <td>5.675593</td>\n",
       "      <td>5.643253</td>\n",
       "      <td>4.569329</td>\n",
       "      <td>6.902848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss23_median</th>\n",
       "      <td>5.813782</td>\n",
       "      <td>5.780655</td>\n",
       "      <td>4.714595</td>\n",
       "      <td>7.088502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss23_std</th>\n",
       "      <td>1.024898</td>\n",
       "      <td>1.019058</td>\n",
       "      <td>0.826257</td>\n",
       "      <td>1.228361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss23_quart25</th>\n",
       "      <td>6.096465</td>\n",
       "      <td>6.061727</td>\n",
       "      <td>4.977320</td>\n",
       "      <td>7.351869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_rss23_quart75</th>\n",
       "      <td>5.531720</td>\n",
       "      <td>5.500200</td>\n",
       "      <td>4.491861</td>\n",
       "      <td>6.669979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss23_max</th>\n",
       "      <td>2.518921</td>\n",
       "      <td>2.504568</td>\n",
       "      <td>2.265310</td>\n",
       "      <td>2.772211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss23_min</th>\n",
       "      <td>0.045838</td>\n",
       "      <td>0.045577</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.091154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss23_mean</th>\n",
       "      <td>1.154812</td>\n",
       "      <td>1.148232</td>\n",
       "      <td>1.088925</td>\n",
       "      <td>1.238944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss23_median</th>\n",
       "      <td>1.086474</td>\n",
       "      <td>1.080284</td>\n",
       "      <td>1.019238</td>\n",
       "      <td>1.171334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss23_std</th>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.514668</td>\n",
       "      <td>0.487377</td>\n",
       "      <td>0.552818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss23_quart25</th>\n",
       "      <td>0.758584</td>\n",
       "      <td>0.754261</td>\n",
       "      <td>0.704777</td>\n",
       "      <td>0.823159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_rss23_quart75</th>\n",
       "      <td>1.523599</td>\n",
       "      <td>1.514918</td>\n",
       "      <td>1.438809</td>\n",
       "      <td>1.640143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   STD_Deviation  CI_value  CI_Lower_Bound  CI_Upper_Bound\n",
       "avg_rss12_max           4.394362  4.369322        3.478739        5.412790\n",
       "avg_rss12_min           9.569975  9.515445        8.300624       10.808411\n",
       "avg_rss12_mean          5.335718  5.305314        4.759450        5.920412\n",
       "avg_rss12_median        5.440054  5.409056        4.845730        6.061634\n",
       "avg_rss12_std           1.772153  1.762056        1.586343        1.961788\n",
       "avg_rss12_quart25       6.153590  6.118526        5.627331        6.700252\n",
       "avg_rss12_quart75       5.138925  5.109643        4.410991        5.913547\n",
       "var_rss12_max           5.062729  5.033882        4.688412        5.476467\n",
       "var_rss12_min           0.000000  0.000000        0.000000        0.000000\n",
       "var_rss12_mean          1.574164  1.565194        1.432934        1.743668\n",
       "var_rss12_median        1.412244  1.404197        1.271341        1.575169\n",
       "var_rss12_stdt          0.884105  0.879068        0.822445        0.958607\n",
       "var_rss12_quart25       0.946386  0.940994        0.852758        1.055922\n",
       "var_rss12_quart75       2.125266  2.113157        1.941150        2.342372\n",
       "avg_rss13_max           4.875137  4.847358        4.263871        5.545271\n",
       "avg_rss13_min           2.956462  2.939616        2.787780        3.132728\n",
       "avg_rss13_mean          4.008380  3.985540        3.512224        4.576050\n",
       "avg_rss13_median        4.036396  4.013397        3.519310        4.609368\n",
       "avg_rss13_std           0.946710  0.941316        0.768252        1.125151\n",
       "avg_rss13_quart25       4.220658  4.196608        3.725250        4.796682\n",
       "avg_rss13_quart75       4.171628  4.147858        3.628029        4.772442\n",
       "var_rss13_max           2.183625  2.171183        1.994477        2.379343\n",
       "var_rss13_min           0.000000  0.000000        0.000000        0.000000\n",
       "var_rss13_mean          1.166114  1.159470        1.104503        1.252509\n",
       "var_rss13_median        1.145586  1.139058        1.083690        1.229823\n",
       "var_rss13_std           0.458242  0.455631        0.428047        0.491386\n",
       "var_rss13_quart25       0.843620  0.838813        0.791059        0.908600\n",
       "var_rss13_quart75       1.552504  1.543658        1.468470        1.666061\n",
       "avg_rss23_max           5.741238  5.708524        4.905496        6.688121\n",
       "avg_rss23_min           6.124001  6.089107        4.717083        7.794325\n",
       "avg_rss23_mean          5.675593  5.643253        4.569329        6.902848\n",
       "avg_rss23_median        5.813782  5.780655        4.714595        7.088502\n",
       "avg_rss23_std           1.024898  1.019058        0.826257        1.228361\n",
       "avg_rss23_quart25       6.096465  6.061727        4.977320        7.351869\n",
       "avg_rss23_quart75       5.531720  5.500200        4.491861        6.669979\n",
       "var_rss23_max           2.518921  2.504568        2.265310        2.772211\n",
       "var_rss23_min           0.045838  0.045577        0.013125        0.091154\n",
       "var_rss23_mean          1.154812  1.148232        1.088925        1.238944\n",
       "var_rss23_median        1.086474  1.080284        1.019238        1.171334\n",
       "var_rss23_std           0.517617  0.514668        0.487377        0.552818\n",
       "var_rss23_quart25       0.758584  0.754261        0.704777        0.823159\n",
       "var_rss23_quart75       1.523599  1.514918        1.438809        1.640143"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "iii. Estimate the standard deviation of each of the time-domain features you\n",
    "extracted from the data. Then, use Python’s bootstrapped or any other\n",
    "method to build a 90% bootsrap confidence interval for the standard deviation\n",
    "of each feature.\n",
    "'''\n",
    "\n",
    "def calculate_std_deviation(time_feature_table):\n",
    "    std_estimate = pd.DataFrame(time_feature_table.std())\n",
    "    std_estimate.columns=['STD_Deviation']\n",
    "    return std_estimate\n",
    "\n",
    "\n",
    "def calculate_CI(std_estimate,time_feature_table):\n",
    "    confidence_intervals=pd.DataFrame(columns=[\"CI for Standard Deviation\"])\n",
    "    \n",
    "    lower_bound=pd.DataFrame(columns=[\"CI_Lower_Bound\"])\n",
    "    upper_bound=pd.DataFrame(columns=[\"CI_upper_bound\"])\n",
    "    \n",
    "    for i,colname in enumerate(time_feature_table):\n",
    "        \n",
    "        arr=np.asarray(time_feature_table[colname]).astype(np.float64)\n",
    "        feature_CI = bs.bootstrap(arr,stat_func = boot_stats.std,alpha=0.1)\n",
    "        \n",
    "        confidence_intervals.loc[colname] = feature_CI.value\n",
    "        lower_bound.loc[colname]=feature_CI.lower_bound\n",
    "        upper_bound.loc[colname]=feature_CI.upper_bound\n",
    "        \n",
    "    Bootstrap_SD=pd.concat([std_estimate,confidence_intervals, lower_bound,upper_bound ],ignore_index=True, axis=1)\n",
    "    Bootstrap_SD.columns=['STD_Deviation','CI_value','CI_Lower_Bound', 'CI_Upper_Bound']\n",
    "    return Bootstrap_SD\n",
    "\n",
    "\n",
    "\n",
    "std_dev = calculate_std_deviation(time_feature_table)\n",
    "Bootstrap_CI = calculate_CI(std_dev,time_feature_table)\n",
    "\n",
    "print(\"\\nEstimated Standard Deviation and their 90% bootsrap confidence interval (CI) for the standard deviation of each feature\\n\")\n",
    "Bootstrap_CI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "Following three time-domain features can be considered most important: <br>\n",
    "1. Mean: It is the best measure of central tendency when the data distribution is continuous. <br>\n",
    "2. Standard Deviation: It is an ideal measure of dispersion. <br>\n",
    "3. Median: It is a good feature of central tendency that is less affected by outliers and skewed data. <br><br>\n",
    "    \n",
    "These are the time domain features which will give us a better idea about the curve and the underlying patterns, hence can be considered important.\n",
    "</font>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "(a) Suppose that the true relationship between X and Y is linear,\n",
    "i.e. Y = β0 + β1X + . Consider the training residual sum of\n",
    "squares (RSS) for the linear regression, and also the training\n",
    "RSS for the cubic regression. Would we expect one to be lower\n",
    "than the other, would we expect them to be the same, or is there\n",
    "not enough information to tell? Justify your answer. <br>\n",
    "\n",
    "\n",
    "\n",
    "Solution: <br>\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "According to given information,training RSS of cubic regression will be lower(Better) as compared to linear regression model.\n",
    "The training RSS is going to decrease as we use more flexible modles, such as this cubic model. \n",
    "This is because it could make a tighter fit against data that matched with a wider irreducible error E. ALso, it is easier to get the predicted line closer to the observations when there is more flexibility how the output function can conform to the data.\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: <br>\n",
    "Answer (a) using test rather than training RSS. <br>\n",
    "\n",
    "Solution: <br>\n",
    "\n",
    "<font color='blue'>\n",
    "    \n",
    " \n",
    "Testing RSS of cubic regression will be higher as compared to linear regression model as the overfit from training would have more error than the linear regression.\n",
    "    \n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: <br>\n",
    "\n",
    "(c) Suppose that the true relationship between X and Y is not linear,\n",
    "but we don’t know how far it is from linear. Consider the training\n",
    "RSS for the linear regression, and also the training RSS for the\n",
    "cubic regression. Would we expect one to be lower than the\n",
    "other, would we expect them to be the same, or is there not\n",
    "enough information to tell? Justify your answer. <br>\n",
    "\n",
    "Solution: <br>\n",
    "<font color='blue'>\n",
    "According to given information, the training RSS for cubic regression will be lower than that of linear regression's  training RSS. This is because the cubic model is more flexible than the linear model. Due to higher flexibility the cublic model could fit the non linearity among the data points better than the linear regression and hence lowering the train RSS.\n",
    "</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "(d) Answer (c) using test rather than training RSS.\n",
    "\n",
    "\n",
    "Solution:  <br>\n",
    "\n",
    "<font color='blue'>\n",
    "    \n",
    "We cannot comment on the testing RSS of both models presented here. The information on the amount of linearity/non linearity is not clear. We do not know how close/away from being linear are X and Y. So if X and Y are close to being linear then the testing RSS of linear model will be lower. But if X and Y are far from being linear then the testing RSS of cubic model will be lower than the linear regression model.\n",
    "    \n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
